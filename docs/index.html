<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PseudoCal: Towards Initialisation-Free Deep Learning-Based Camera-LiDAR Self-Calibration</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">
  <link rel="stylesheet" href="style.css">
</head>

<body>
  <section class="bg-body-secondary">
    <div class="container text-center p-4">
      <h1>PseudoCal: Towards Initialisation-Free Deep Learning-Based Camera-LiDAR Self-Calibration</h1>
      <h3 class="text-secondary">BMVC (British Machine Vision Conference) 2023</h3>
      <hr>
      <p>
        <a href="https://www.cocheteux.eu">Mathieu Cocheteux</a>,
        <a href="https://www.hds.utc.fr/~moreajul">Julien Moreau</a>,
        <a href="https://www.hds.utc.fr/~fdavoine">Franck Davoine</a> <br>
        Université de technologie de Compiègne, CNRS<br>
        Heudiasyc Laboratory<br>
        France
      </p>
      <div class="all-links">
        <a href="https://proceedings.bmvc2023.org/829/" target="_blank" rel="noopener noreferrer"
  class="btn btn-danger" role="button"><img src="./logos/document.svg" height="30" /
    class="my-1"><br>Proceedings</a>
        <a href="https://arxiv.org/pdf/2309.09855.pdf" target="_blank" rel="noopener noreferrer" class="btn btn-primary"
          role="button"><img src="./logos/document.svg" height="30" / class="my-1"><br>arXiv</a>
        <a href="https://www.youtube.com/watch?v=KnmY14g7O1M" target="_blank" rel="noopener noreferrer"
          class="btn btn-danger" role="button"><img src="./logos/youtube.svg" height="30" /
            class="my-1"><br>Presentation</a>
      </div>
    </div>
  </section>
  <section>
    <div class="container p-4">
      <center>
        <iframe src="https://www.youtube.com/embed/KnmY14g7O1M?si=DQI1xF4GgbvKLsO1" title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen style="width: 56vw; 
            height: 31.5vw;"></iframe>
      </center>
      <hr class="my-4">
      <h5>Abstract</h5>
      <p>Camera-LiDAR extrinsic calibration is a critical task for multi-sensor fusion in autonomous systems, such as
        self-driving vehicles and mobile robots. Traditional techniques often require manual intervention or specific
        environments, making them labour-intensive and error-prone. Existing deep learning-based self-calibration
        methods focus on small realignments and still rely on initial estimates, limiting their practicality. In this
        paper, we present PseudoCal, a novel self-calibration method that overcomes these limitations by leveraging the
        pseudo-LiDAR concept and working directly in the 3D space instead of limiting itself to the camera field of
        view. In typical autonomous vehicle and robotics contexts and conventions, PseudoCal is able to perform one-shot
        calibration quasi-independently of initial parameter estimates, addressing extreme cases that remain unsolved by
        existing approaches.</p>
      <hr class="my-4">
      <h5>Citation</h5>
      <pre class="bg-body-secondary px-3 py-3"><code>@inproceedings{Cocheteux_2023_BMVC,
<!-- -->    author    = {Mathieu Cocheteux and Julien Moreau and Franck Davoine},
<!-- -->    title     = {PseudoCal: Towards Initialisation-Free Deep Learning-Based Camera-LiDAR Self-Calibration},
<!-- -->    booktitle = {34th British Machine Vision Conference 2023, {BMVC} 2023, Aberdeen, UK, November 20-24, 2023},
<!-- -->    publisher = {{BMVA}},
<!-- -->    year      = {2023},
<!-- -->    url       = {https://papers.bmvc2023.org/0829.pdf}
<!-- -->    }
        </code></pre>
      <hr class="my-4">
    </div>
  </section>
</body>

</html>
